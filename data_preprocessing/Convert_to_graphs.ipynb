{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Convert_to_graphs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHRF2rpmeV3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aa076f4-52d8-4d19-885e-53dc75365618"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gARG4hGNerj5",
        "outputId": "622c995a-e137-42d1-d93f-664e7edf9852"
      },
      "source": [
        "cd drive/My Drive/google_colab_gpu/CMS_Graphs"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/google_colab_gpu/CMS_Graphs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L0QfLOCeuIZ",
        "outputId": "8de82ca6-bf4f-4715-dce8-904908644e15"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.9.0+cu102\n",
            "10.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4YiCOp9fH8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a8248a8-62f1-4a57-c1fb-9226f81a5853"
      },
      "source": [
        "# Install required packages.\n",
        "!pip install progress progressbar2 alive-progress tqdm\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-geometric"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting progress\n",
            "  Downloading progress-1.6.tar.gz (7.8 kB)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.7/dist-packages (3.38.0)\n",
            "Collecting alive-progress\n",
            "  Downloading alive_progress-1.6.2-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from progressbar2) (1.15.0)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2) (2.5.6)\n",
            "Building wheels for collected packages: progress\n",
            "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progress: filename=progress-1.6-py3-none-any.whl size=9628 sha256=a8453350450204a3779d27755ebc82ca9458ea68f47755f295f25e10145a5643\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/d7/61/498d8e27dc11e9805b01eb3539e2ee344436fc226daeb5fe87\n",
            "Successfully built progress\n",
            "Installing collected packages: progress, alive-progress\n",
            "Successfully installed alive-progress-1.6.2 progress-1.6\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_scatter-2.0.8-cp37-cp37m-linux_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 2.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.8\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_sparse-0.6.11-cp37-cp37m-linux_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.11\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (926 kB)\n",
            "\u001b[K     |████████████████████████████████| 926 kB 2.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.5.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (382 kB)\n",
            "\u001b[K     |████████████████████████████████| 382 kB 2.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-1.7.2.tar.gz (222 kB)\n",
            "\u001b[K     |████████████████████████████████| 222 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.2)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.15)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.0.0-py3-none-any.whl (376 kB)\n",
            "\u001b[K     |████████████████████████████████| 376 kB 41.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.7.2-py3-none-any.whl size=388143 sha256=fd87859477adac72317433983de8ee104b3366d746bf7e12f91f7c7c2abe7160\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/93/b6/2eeb0465afe89aee74d7a07a606e9770466d7565abd45a99d5\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.0 rdflib-6.0.0 torch-geometric-1.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "CzZTOdACe1T7",
        "outputId": "b16575b4-a073-4400-c510-c9e457e842df"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "'''\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printm()\n",
        "'''"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=d2ad7f7a1303face9006b72d1d702b19daa7225ae588399f7376f00c54fa4053\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# XXX: only one GPU on Colab and isn’t guaranteed\\ngpu = GPUs[0]\\ndef printm():\\n  process = psutil.Process(os.getpid())\\n  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\\n  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\\n\\nprintm()\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHtLXjv9e303"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "import os, glob\n",
        "import time\n",
        "import h5py\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils\n",
        "import torch.utils.data\n",
        "from torch.utils.data import ConcatDataset, Dataset, DataLoader, sampler, DistributedSampler\n",
        "#from torch.utils.data import *\n",
        "from sklearn.metrics import roc_curve, auc"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y38NL2j8e59u"
      },
      "source": [
        "import argparse\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "parser = argparse.ArgumentParser()\n",
        "#parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n",
        "parser.add_argument('--epochs', type=int, default=50, help='Number of epochs to train.')\n",
        "parser.add_argument('--batch_size', type=int, default=64, help='Initial learning rate.') #100\n",
        "parser.add_argument('--maxnodes', type=int, default=1000, help='max nodes.') #100\n",
        "parser.add_argument('--lr', type=float, default=0.001, help='Initial learning rate.') #0.001\n",
        "parser.add_argument('--dropout', type=float, default=0.3, help='Dropout rate (1 - keep probability).')\n",
        "args = parser.parse_args([])\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGhyb1h3e705"
      },
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "class ParquetDataset(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.parquet = pq.ParquetFile(filename)\n",
        "        self.cols = None # read all columns\n",
        "        #self.cols = ['X_jets.list.item.list.item.list.item','y'] \n",
        "    def __getitem__(self, index):\n",
        "        data = self.parquet.read_row_group(index, columns=self.cols).to_pydict()\n",
        "        #print(data.keys())\n",
        "        data['X_jets'] = torch.tensor(np.float32(data['X_jets'])) \n",
        "        data['y'] = torch.tensor(np.float32(data['y']))\n",
        "        #data['m0'] = torch.tensor(np.float32(data['m0']))\n",
        "        #data['pt'] = torch.tensor(np.float32(data['pt']))\n",
        "        data['X_jets'][data['X_jets'] < 1.e-3] = 0.\n",
        "        # Preprocessing\n",
        "        #data['nonzeroPixels'][data['nonzeroPixels'] < 1.e-3] = 0. # Zero-Suppression\n",
        "        #data['nonzeroPixels'][-1,...] = 25.*data['nonzeroPixels'][-1,...] # For HCAL: to match pixel intensity distn of other layers\n",
        "        #data['nonzeroPixels'] = data['nonzeroPixels']/100. # To standardize\n",
        "        return dict(data)\n",
        "    def __len__(self):\n",
        "        return self.parquet.num_row_groups"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaE_b2x68iW2",
        "outputId": "5142ccad-e9c1-4cb6-acdf-edfcf4b164a2"
      },
      "source": [
        "# Boosted Top Jets\n",
        "decays = glob.glob('./data_shared/BoostedTopParquet_x1_fixed_images/*.parquet')\n",
        "print(\">> Train files: \",decays)\n",
        "dset_train = ConcatDataset([ParquetDataset(d) for d in decays])\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">> Train files:  ['./data_shared/BoostedTopParquet_x1_fixed_images/BoostedTop_x1_samples_0_0_to_99_3199.parquet', './data_shared/BoostedTopParquet_x1_fixed_images/BoostedTop_x1_samples_100_0_to_199_3199.parquet', './data_shared/BoostedTopParquet_x1_fixed_images/BoostedTop_x1_samples_200_0_to_299_3199.parquet', './data_shared/BoostedTopParquet_x1_fixed_images/BoostedTop_x1_samples_300_0_to_399_3199.parquet']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTg5rltafS0l"
      },
      "source": [
        "## generate list to count nodes for each graph\n",
        "def nodeCounter(samples):\n",
        "    inds=[]\n",
        "    for k in samples:\n",
        "        inds.append(k['x'].shape[0])\n",
        "    return inds\n",
        "\n",
        "def ref(bsize,nodeC,i1,i2):\n",
        "  maxC=np.max(np.array(nodeC))\n",
        "  maxC=args.maxnodes#maxC + (4 - maxC % 4) ##max num of nodes 1161%4\n",
        "  refMat=np.zeros((bsize,maxC)) ## matrix of zeros\n",
        "  for pi in range(i1,i2):##10\n",
        "    refMat[pi,:nodeC[pi]]=1 ## fill ones \n",
        "  return refMat,maxC\n",
        "\n",
        "def assigner(nodelist):\n",
        "  fin=[]\n",
        "  countit=0\n",
        "  for m in nodelist:\n",
        "      fin.append(np.repeat(countit,m))\n",
        "      countit+=1\n",
        "  return np.array(fin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApsgTc5bgCsD"
      },
      "source": [
        "# Boosted Top Jets without GPU\n",
        "import torch_geometric.transforms\n",
        "from torch_geometric.nn import knn_graph\n",
        "import torch_geometric.data\n",
        "import torch \n",
        "from torch_geometric.data import Data\n",
        "import numpy as np\n",
        "from google.colab import output\n",
        "import pandas as pd\n",
        "import pyarrow.parquet as pq\n",
        "from progress.bar import Bar\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def progress(value, max=3200):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 75%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))\n",
        "\n",
        "def convert_to_graph(train_data, start_idx, end_idx, granularity=1, new_file=False):   # input data format should be [N,C,H,W]\n",
        "    print('Processing idx nos. from '+str(start_idx)+' to '+str(end_idx))\n",
        "    out = display(progress(start_idx, end_idx), display_id=True)\n",
        "    for idx in range(start_idx,end_idx):\n",
        "\n",
        "      data=train_data[idx]['X_jets']\n",
        "      min_pixel_val = torch.min(data)\n",
        "      max_pixel_val = torch.max(data)\n",
        "      image3D = data.reshape(125*granularity,125*granularity,8)\n",
        "      Hcal_frame = torch.zeros_like(image3D[:,:,4])\n",
        "      for i in range(0,image3D.shape[0]):\n",
        "        for j in range(0,image3D.shape[1]):\n",
        "          if (i-2)%5 == 0:\n",
        "            if (j-2)%5 == 0:\n",
        "              Hcal_frame[i,j] = torch.sum(image3D[i-2:i+3,j-2:j+3,4]) \n",
        "            else:\n",
        "              Hcal_frame[i,j] = 0.\n",
        "          else:\n",
        "            Hcal_frame[i,j] = 0.\n",
        "      image3D[:,:,4] = Hcal_frame\n",
        "      nonzero_pos = torch.nonzero(image3D, as_tuple=True)\n",
        "      coords = torch.cat((torch.unsqueeze(nonzero_pos[0],dim=1), torch.unsqueeze(nonzero_pos[1],dim=1)),dim=1).float()\n",
        "      coords = (coords.float() - 62)/62\n",
        "      \n",
        "      Ecal = torch.unsqueeze(image3D[nonzero_pos[0],nonzero_pos[1],3],dim=1)\n",
        "      dz = torch.unsqueeze(image3D[nonzero_pos[0],nonzero_pos[1],2],dim=1)\n",
        "      d0 = torch.unsqueeze(image3D[nonzero_pos[0],nonzero_pos[1],1],dim=1)\n",
        "      Hcal = torch.unsqueeze(image3D[nonzero_pos[0],nonzero_pos[1],4],dim=1)\n",
        "      pT = torch.unsqueeze(image3D[nonzero_pos[0],nonzero_pos[1],0],dim=1)\n",
        "      BPIX1 = torch.unsqueeze(image3D[nonzero_pos[0],nonzero_pos[1],5],dim=1)\n",
        "      BPIX2 = torch.unsqueeze(image3D[nonzero_pos[0],nonzero_pos[1],6],dim=1)\n",
        "      BPIX3 = torch.unsqueeze(image3D[nonzero_pos[0],nonzero_pos[1],7],dim=1)\n",
        "      feats = torch.cat((coords[:,0:1],coords[:,1:], pT, d0, dz, Ecal, Hcal, BPIX1, BPIX2, BPIX3), dim=1)\n",
        "      feats = torch.unique(feats,dim=0)\n",
        "      edge_index = knn_graph(feats[:,0:2], k=16, batch=None, loop=True)  ## Create knn graph adjacency matrix\n",
        "      #print(coords.shape, edge_index.shape, pT.shape, Ecal.shape, Hcal.shape, dz.shape, d0.shape, BPIX1.shape, BPIX2.shape, BPIX3.shape)\n",
        "      \n",
        "      #parquet_Dataframe = pd.DataFrame({'coords0':[np.array(coords[:,0].cpu())], 'coords1':[np.array(coords[:,1].cpu())], 'edge_index_from': [np.array(edge_index[0,:].cpu())], 'edge_index_to': [np.array(edge_index[1,:].cpu())], 'pT': [np.array(torch.squeeze(pT).cpu())], 'ECAL':[np.array(torch.squeeze(Ecal).cpu())], 'HCAL':[np.array(torch.squeeze(Hcal).cpu())], 'd0':[np.array(torch.squeeze(d0).cpu())], 'dz':[np.array(torch.squeeze(dz).cpu())], 'BPIX1':[np.array(torch.squeeze(BPIX1).cpu())], 'BPIX2': [np.array(torch.squeeze(BPIX2).cpu())], 'BPIX3': [np.array(torch.squeeze(BPIX3).cpu())], 'y':np.array(train_data[idx]['y']), 'tfrecord': train_data[idx]['tfrecord'], 'm0': train_data[idx]['m0'], 'pT_jet': train_data[idx]['pt']})\n",
        "      parquet_Dataframe = pd.DataFrame({'coords0':[np.array(feats[:,0].cpu())],'coords1':[np.array(feats[:,1].cpu())],'edge_index_from': [np.array(edge_index[0,:].cpu())],'edge_index_to': [np.array(edge_index[1,:].cpu())],'pT':[np.array(feats[:,2].cpu())],'d0':[np.array(feats[:,3].cpu())],'dz':[np.array(feats[:,4].cpu())],'ECAL':[np.array(feats[:,5].cpu())],'HCAL':[np.array(feats[:,6].cpu())],'BPIX1':[np.array(feats[:,7].cpu())],'BPIX2':[np.array(feats[:,8].cpu())],'BPIX3':[np.array(feats[:,9].cpu())],'y':np.array(train_data[idx]['y']), 'tfrecord': train_data[idx]['tfrecord'], 'm0': train_data[idx]['m0'], 'pT_jet': train_data[idx]['pt']})\n",
        "      table = pa.Table.from_pandas(parquet_Dataframe)\n",
        "      #print(type(table.schema), type(table))\n",
        "      \n",
        "      if (new_file):\n",
        "      # create a parquet write object giving it an output file\n",
        "        output_filename = 'data_shared/BoostedTopParquet_x1_fixed_Graphs/BoostedTop_x1_train_samples_'+str(start_idx)+'_to_'+str(end_idx-1)+'.parquet'\n",
        "        pqwriter = pq.ParquetWriter(output_filename,table.schema,compression='snappy')\n",
        "        new_file=False\n",
        "      pqwriter.write_table(table)\n",
        "      out.update(progress(idx, end_idx))\n",
        "      if (idx%3200==0):\n",
        "        print(\"Current idx: \",str(idx))\n",
        "\n",
        "    if pqwriter:\n",
        "      pqwriter.close()\n",
        "\n",
        "    return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "xlWS13v_fWZ0",
        "outputId": "e7f0363c-7f87-46d2-8ec2-5e269cd2a6b8"
      },
      "source": [
        "# Boosted Top Jets\n",
        "convert_to_graph(dset_train,6400*50,6400*51,granularity=1,new_file=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing idx nos. from 320000 to 326400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='326399'\n",
              "            max='326400',\n",
              "            style='width: 75%'\n",
              "        >\n",
              "            326399\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Current idx:  320000\n",
            "Current idx:  323200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "id": "086c8HGt9jeU",
        "outputId": "0f66a780-68a4-43ef-f1e9-0761c8ac9e60"
      },
      "source": [
        "# Boosted Top Jets\n",
        "convert_to_graph(dset_train,6400*51,6400*52,granularity=1,new_file=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing idx nos. from 326400 to 332800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='332680'\n",
              "            max='332800',\n",
              "            style='width: 75%'\n",
              "        >\n",
              "            332680\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Current idx:  326400\n",
            "Current idx:  329600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='332799'\n",
              "            max='332800',\n",
              "            style='width: 75%'\n",
              "        >\n",
              "            332799\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNSSuPOKA2-s",
        "outputId": "f9640b8a-7c69-429c-dcac-d808233ce32d"
      },
      "source": [
        "dset_train[640000-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'X_jets': tensor([[0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " 'm0': tensor([69.3547]),\n",
              " 'pt': tensor([626.9458]),\n",
              " 'tfrecord': ['data_shared/BoostedTop_x1_fixed_tfrecord/BoostedJets_fullSample_x1_file-143'],\n",
              " 'y': tensor([0.])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8C0etrOq5Cx"
      },
      "source": [
        "tp = dset_test[75]['ECAL'].detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX7OxCx8v246",
        "outputId": "130a0d79-31f6-48b6-cdb5-6b78f5f792b3"
      },
      "source": [
        "dset_test[75]['ECAL'][-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWWwHHNuwhvp"
      },
      "source": [
        "tp[-1]-=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnuHzkPxxjBP",
        "outputId": "89fd5b6e-1420-4a53-9885-b75ac615e132"
      },
      "source": [
        "tp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0212, 0.0212, 0.0521,  ..., 0.0000, 0.0000, 0.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PSYBXo4xj2V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}